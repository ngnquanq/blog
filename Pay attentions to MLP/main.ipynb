{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from random import randrange\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, einsum\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Gating Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialGatingUnit(nn.Module):\n",
    "    def __init__(self, d_ffn, \n",
    "                 seq_len, weight_value=0.05):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_ffn//2)\n",
    "        \n",
    "        # Setup weight for the spatial projection\n",
    "        self.weight = nn.Parameter(torch.zeros(seq_len,seq_len))\n",
    "        nn.init.uniform_(self.weight, a=-weight_value, b=weight_value)\n",
    "        \n",
    "        # Setup bias for the spatial projection\n",
    "        self.bias = nn.Parameter(torch.ones(seq_len))\n",
    "\n",
    "    def forward(self, x):\n",
    "        u, v = x.chunk(2, dim=-1)\n",
    "        v = self.norm(v)\n",
    "        \n",
    "        weight, bias = self.weight, self.bias\n",
    "        v = einsum('b n d, m n -> b m d', v, weight) + rearrange(bias, 'n -> () n ()')\n",
    "        return u * v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated-MLP Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLPBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ffn, seq_len):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.channel_proj_U = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ffn),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.sgu = SpatialGatingUnit(d_ffn, seq_len)\n",
    "        self.channel_proj_V = nn.Sequential(\n",
    "            nn.Linear(d_ffn//2, d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.norm(x)\n",
    "        x = self.channel_proj_U(x)\n",
    "        x = self.sgu(x)\n",
    "        x = self.channel_proj_V(x)\n",
    "        return x + res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated_MLP model with L Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLP(nn.Module):\n",
    "    def __init__(self, d_model, d_ffn, seq_len, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(gMLPBlock(d_model, d_ffn, seq_len))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, criterion, test_dataloader, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, save_model, optimizer, criterion,\n",
    "          train_dataloader, test_dataloader, num_epochs, device,\n",
    "          csv_filename):\n",
    "    train_accs, train_losses = [], []\n",
    "    eval_accs, eval_losses = [], []\n",
    "    best_loss_eval = 100\n",
    "    times = []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_acc, train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device, epoch)\n",
    "        train_accs.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        eval_acc, eval_loss = evaluate_epoch(model, criterion, test_dataloader, device)\n",
    "        eval_accs.append(eval_acc)\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        if eval_loss < best_loss_eval:\n",
    "            torch.save(model.state_dict(), save_model + f'/{model_name}.pt')\n",
    "\n",
    "        times.append(time.time() - epoch_start_time)\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "            \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "                epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)\n",
    "\n",
    "    model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
    "    model.eval()\n",
    "\n",
    "    # Create a DataFrame from the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Epoch': list(range(1, num_epochs+1)),\n",
    "        'Train Accuracy': train_accs,\n",
    "        'Train Loss': train_losses,\n",
    "        'Valid Accuracy': eval_accs,\n",
    "        'Valid Loss': eval_losses,\n",
    "        'Time': times\n",
    "    })\n",
    "\n",
    "    # Write the DataFrame to a CSV file with a specified sheet name\n",
    "    metrics_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, loss_fn):\n",
    "    \"\"\"Test loop.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target.squeeze()).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            all_preds.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = (100. * correct / len(test_loader.dataset))/100\n",
    "\n",
    "    # Calculate additional metrics without using classification_report\n",
    "    precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    # Round the metrics to two decimal places\n",
    "    accuracy = round(accuracy, 2)\n",
    "    precision = round(precision, 2)\n",
    "    recall = round(recall, 2)\n",
    "    f1 = round(f1, 2)\n",
    "\n",
    "    # Return the metrics as a dictionary\n",
    "    metrics_dict = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Recall\": recall,\n",
    "        \"Precision\": precision\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses):\n",
    "    epochs = list(range(num_epochs))\n",
    "    fig, axs = plt.subplots(nrows = 1, ncols =2 , figsize = (12,6))\n",
    "    axs[0].plot(epochs, train_accs, label = \"Training\")\n",
    "    axs[0].plot(epochs, eval_accs, label = \"Evaluation\")\n",
    "    axs[1].plot(epochs, train_losses, label = \"Training\")\n",
    "    axs[1].plot(epochs, eval_losses, label = \"Evaluation\")\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.CIFAR10('./CIFAR10_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.CIFAR10('./CIFAR10_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create the dataloaders\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, thì cho ai chưa biết thì cái protocol của cái gMLP này là các tác giả sẽ xét như cái ViT/16 luôn, nhưng mà cái shape này có 32x32 à nên là chia 16x16 thì nó kì kì =)))))))))))))))). Nên là thay vào đó thì mình xét nó là ViT/8 (bịa đó), thì nó sẽ chia cái input từ 32 x 32 vào còn 16 cái 8 x 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, patch_size, in_channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, embed_dim, H, W)\n",
    "        return x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cái class mới này về cơ bản là cũng như cái ở trên thôi, nma cái ở trên nó có cái bước proj nữa nên là mình kh muốn phải return 2 kết quả (kiểu khó kiểm soát lúc code đoạn sau) nên mình tạo class mới y đúc class cũ thiếu mỗi quả projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtractor(nn.Module):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # Split the image into patches\n",
    "        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        x = x.permute(0, 2, 3, 1, 4, 5).reshape(B, -1, C, self.patch_size, self.patch_size)\n",
    "        return x\n",
    "\n",
    "# Initialize the PatchExtractor module\n",
    "patch_extract = PatchExtractor(patch_size=8)\n",
    "\n",
    "# Get one image from the train data\n",
    "image, label = next(iter(trainloader))\n",
    "\n",
    "# Select the first image in the batch\n",
    "image = image[0].unsqueeze(0)  # Add an extra dimension for the batch size\n",
    "\n",
    "# Apply the PatchExtractor module\n",
    "patches = patch_extract(image)\n",
    "\n",
    "# Convert the patches to numpy arrays and visualize them\n",
    "patches = patches.numpy()\n",
    "n_patches = patches.shape[1]\n",
    "fig, axs = plt.subplots(1, n_patches, figsize=(n_patches*2, 2))\n",
    "# Suppress warnings\n",
    "for i, ax in enumerate(axs):\n",
    "    patch = np.transpose(patches[0, i], (1, 2, 0))\n",
    "    patch = np.clip(patch, 0, 1)  # Clip to the range [0, 1] to avoid overexposure\n",
    "    ax.imshow(patch)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLP_Vision(nn.Module):\n",
    "    def __init__(self, patch_size = 8, num_patches = 16, embed_dim = 768, num_layers = 6):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(patch_size=patch_size, in_channels=3, embed_dim=embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=0.1)\n",
    "\n",
    "        self.blocks = gMLP(d_model=embed_dim,\n",
    "                           d_ffn=embed_dim*4, \n",
    "                           seq_len=num_patches+1, \n",
    "                           num_layers=num_layers)\n",
    "\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Classification(nn.Module):\n",
    "    def __init__(self, patch_size = 8, num_patches = 16, embed_dim = 512, \n",
    "                 num_layers = 3, fc_dim = 256, num_classes = 10):\n",
    "        super().__init__()\n",
    "        self.model = gMLP_Vision(patch_size=patch_size, num_patches=num_patches, embed_dim=embed_dim, num_layers=num_layers)\n",
    "        self.fc_1 = nn.Linear(embed_dim, fc_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.head = nn.Linear(fc_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Image_Classification()\n",
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters())\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), \n",
    "                  lr=1e-4)\n",
    "criterion = CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "os.makedirs(save_model, exist_ok = True)\n",
    "model_name = 'Image_Classification'\n",
    "\n",
    "model, metrics = train(\n",
    "    model, model_name, save_model, optimizer, criterion,\n",
    "    trainloader, testloader, num_epochs, device, 'Image_Classification.csv'\n",
    ")\n",
    "\n",
    "save_path = os.path.join(save_model, f\"{model_name}.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model weights saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=)))))))))))))))) ok nó học được, nma còn hơi cùi, lúc đầu mình set model này cũng lớn 26M tham số nma mình set lại còn 4M tham số cho cái máy mình chạy được, chứ 26M thì nó ngủm đó ae, nma 26M thì vẫn là nhãi con so với big bro gu gồ nên thôi, chủ yếu là chạy cho vui, ae nào máy mạnh mạnh thì cứ mạnh dạn set cái model này bự lên, dù sao thì người ta cũng show ra là có model capacity càng lớn thì model chạy càng chính xác. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi chạy xong thì có vẻ cái top1 hơi khoai cho thằng em, nên lấy cái top5 cho thằng e dễ thở "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch_topk(model, test_dataloader, device, k):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted = predictions.topk(k, 1, True, True)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.view(-1, 1).expand_as(predicted)).sum().item()\n",
    "\n",
    "    top5_acc = correct / total\n",
    "    return top5_acc\n",
    "\n",
    "top5 = evaluate_epoch_topk(model, testloader, device, 5)\n",
    "print(f\"Top-5 accuracy: {top5:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
